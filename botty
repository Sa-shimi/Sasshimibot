import telebot
import random
import networkx as nx
import pandas as pd
from itertools import combinations
from random import randrange
import numpy as np
import matplotlib.pyplot as plt
import time
import multiprocessing as mp




def plottare(iters, steps,num,par):
    m = 0
    def tutto():
        p = par

        F = nx.random_tree(n=num, create_using=nx.DiGraph, )
        G = nx.barabasi_albert_graph(num, p)

        def combine(arr, s):
            return list(combinations(arr, s))

        def Control_Centrality(F):
            length = len(F.nodes)
            i = 1

            def CC(F):
                pippa = F.out_degree()
                pippa1 = np.array(pippa)
                pippa2 = pippa1[pippa1[:, 1] != 0]
                F = F.subgraph(pippa2[:, 0])
                return F

            def layer(F):
                culo = [x for x in F.nodes if x not in CC(F).nodes]
                banana = [i] * len(culo)
                results = np.column_stack((culo, banana))
                return results

            results = layer(F)
            while len(results) < length:
                results = np.concatenate([results, layer(F)])
                results = np.unique(results, axis=0)
                i += 1
                F = CC(F)
                layer(F)
            return dict(zip(results[:, 0], (results[:, 1])))

        BC = nx.betweenness_centrality(F)

        isinstance(BC, dict)
        list(G.nodes)

        lll = combinations(G.nodes(), 2)
        lll = np.matrix(list(lll))
        cliques = list(nx.enumerate_all_cliques(G))
        triads = [i for i in cliques if len(i) == 3]
        simm = []
        for n in triads:
            for l in combine(n, 2):
                simm.append(l)

        simmelian = []
        for i in simm:
            if i not in simmelian:
                simmelian.append(i)

        simmelian = np.array(simmelian)

        A = simmelian[:, 0]
        B = simmelian[:, 1]
        A1 = lll[:, 0]
        B1 = lll[:, 1]
        df = pd.DataFrame(simmelian)
        numsimm = len(simmelian)

        BCA = []
        for x in A:
            for n in BC:
                if x == n:
                    BCA.append(BC[n])
        BCB = []
        for y in B:
            for n in BC:
                if y == n:
                    BCB.append(BC[n])

        df['BCA'] = BCA
        df['BCB'] = BCB
        df['AVG'] = (df['BCA'] + df['BCB']) / 2
        df['VAR'] = (((df['BCA'] - df['AVG']) ** 2 + (df['BCB'] - df['AVG']) ** 2) / 2)
        VAR = np.sum(df['VAR'])
        V = VAR / numsimm
        df1 = df[3:4]
        dff = []
        for k in G.nodes:
            for n in BC:
                if k == n:
                    dff.append(BC[n])
        T = max(dff)

        H = pd.DataFrame(dff)
        H['BCMax'] = T
        H.rename(columns={0: 'BCentrality'}, inplace=True)
        H['Hier'] = (H['BCMax'] - H['BCentrality'])
        Q = np.mean(H['Hier'])
        v = Q * V

        BC1 = nx.betweenness_centrality(F)
        isinstance(BC1, dict)
        df1 = pd.DataFrame(lll)
        BC1A = []
        for x in A1:
            for n in BC1:
                if x == n:
                    BC1A.append(BC1[n])
        BC1B = []
        for y in B1:
            for n in BC1:
                if y == n:
                    BC1B.append(BC1[n])
        df1['BC1A'] = BC1A
        df1['BC1B'] = BC1B
        df1['AVG1'] = (df1['BC1A'] + df1['BC1B']) / 2
        df1['VAR1'] = ((df1['BC1A'] - df1['AVG1']) ** 2 + (df1['BC1B'] - df1['AVG1']) ** 2) / 2
        V1 = np.mean(df1['VAR1'])
        dff1 = []
        for k in G.nodes:
            for n in BC1:
                if k == n:
                    dff1.append(BC1[n])
        T1 = max(dff1)
        H1 = pd.DataFrame(dff1)
        H1['BC1Max'] = T1
        H1.rename(columns={0: 'BCentrality1'}, inplace=True)
        H1['Hier1'] = (H1['BC1Max'] - H1['BCentrality1'])
        Vl = V / V1
        nx.set_edge_attributes(G, 0, name='imitation')
        for n in G.nodes:
            G.nodes[n]['imitation'] = randrange(1, 10) / 100

        sup = []
        for (i, j) in F.edges:
            sup.append((j, i))

        sub = F.edges

        nx.set_edge_attributes(G, 0, name='theta')
        for n in G.nodes:
            G.nodes[n]['theta'] = randrange(1, 10) / 500
        nx.set_edge_attributes(G, 0, name='ego')
        for n in G.nodes:
            G.nodes[n]['ego'] = randrange(4, 9) / 10
        nx.set_node_attributes(G, 0, name='relevance')
        primi = random.sample(range(0, num), 1)

        for n in primi:
            G.nodes[n]['relevance'] = 1

        nx.set_edge_attributes(G, 0, name='threshold')
        for n in G.nodes:
            G.nodes[n]['threshold'] = np.random.beta(1, 10)

        influence_matrix = np.matrix(np.zeros((num, num)))
        for i in G.nodes:
            for j in G.nodes:
                if i != j:
                    if j in G.neighbors(i):
                        if BC[i] - BC[j] < 0:
                            influence_matrix[i, j] = (np.random.beta(1, 8) / len(list(G.neighbors(i))))
                        elif BC[i] - BC[j] > 0:
                            influence_matrix[i, j] = np.random.beta(3, 7) / len(list(G.neighbors(i)))
                        elif BC[i] - BC[j] == 0:
                            influence_matrix[i, j] = np.random.beta(4, 3) / len(list(G.neighbors(i)))
            influence_matrix[i, i] = (1 - influence_matrix[[i]].sum(axis=1))


        probability_matrix = np.matrix(np.zeros((num, num)))
        for i in G.nodes:
            for j in G.nodes:
                if i == j:
                    probability_matrix[i, j] = 1
                elif i != j:
                    if [i, j] in simmelian:
                        if BC[i] - BC[j] > 0:
                            probability_matrix[i, j] = np.random.beta(8, 1)
                        elif BC[i] - BC[j] < 0:
                            probability_matrix[i, j] = np.random.beta(8, 1)
                        elif BC[i] - BC[j] == 0:
                            probability_matrix[i, j] = np.random.beta(8, 1)
                    elif [i, j] not in simmelian:
                        if BC[i] - BC[j] > 0:
                            probability_matrix[i, j] = np.random.beta(4, 2)
                        elif BC[i] - BC[j] < 0:
                            probability_matrix[i, j] = np.random.beta(4, 2)
                        elif BC[i] - BC[j] == 0:
                            probability_matrix[i, j] = np.random.beta(4, 3)

        def degroot(G):
            K = G.copy()
            t = 1
            bellini = []

            def event():
                P = K.copy()
                for i in K.nodes:
                    opchange = [P.nodes[i]['relevance']*influence_matrix[i,i]]
                    for j in K.neighbors(i):
                        if P.nodes[j]['relevance'] >= P.nodes[j]['threshold']:
                            if random.random() < probability_matrix[i, j]:
                                opchange.append(influence_matrix[i, j])

                    opchange.append(P.nodes[i]['relevance'])
                    K.nodes[i]["relevance"] = np.sum(opchange) - K.nodes[i]['theta']
                return K

            dati = [Vl]
            datelli = []
            while t != steps:
                t += 1
                event()
                P = []
                for n in K.nodes:
                    if K.nodes[n]['relevance'] >= K.nodes[n]['threshold']:
                        P.append(K.nodes[n]['relevance'])
                        if n not in bellini:
                            bellini.append(n)
                dati.append((len(P) / num))
                datelli.append((len(bellini) / num))

            return [dati, datelli]

        def contagion(G):
            K = G.copy()
            t = 1
            bellini = []

            def event():
                P = K.copy()
                for i in K.nodes:
                    opchange = [P.nodes[i]['relevance']*influence_matrix[i,i]]
                    for j in K.neighbors(i):
                        if P.nodes[j]['relevance'] >= P.nodes[j]['threshold']:
                            if random.random() < probability_matrix[i, j]:
                                opchange.append(influence_matrix[i, j] * P.nodes[j]['relevance'])
                            if random.random() > probability_matrix[i, j]:
                                opchange.append(influence_matrix[i, j]*P.nodes[i]['relevance'])
                        if P.nodes[j]['relevance'] >= P.nodes[j]['threshold']:
                            opchange.append(influence_matrix[i, j] * P.nodes[i]['relevance'])
                    K.nodes[i]["relevance"] = np.sum(opchange)

                return K

            dati = [Vl]
            datelli = []
            while t != steps:
                t += 1
                event()
                P = []
                for n in K.nodes:
                    if K.nodes[n]['relevance'] >= K.nodes[n]['threshold']:
                        P.append(K.nodes[n]['relevance'])
                        if n not in bellini:
                            bellini.append(n)
                dati.append((len(P) / num))
                datelli.append((len(bellini) / num))

            return [dati, datelli]

        def bass(G):
            K = G.copy()
            t = 1
            bellini = []

            def event(G):
                nonsimmy = []
                simmy = []
                for i in K.nodes:
                    if K.nodes[i] in simmelian:
                        if K.nodes[i]['relevance'] > K.nodes[i]['threshold']:
                            simmy.append(n)
                    if K.nodes[i] not in simmelian:
                        if K.nodes[i]['relevance'] > K.nodes[i]['threshold']:
                            nonsimmy.append(i)
                prob = ((len(simmy) * Vl) + len(nonsimmy)) / len(G.nodes)
                for i in K.nodes:
                    if K.nodes[i]['relevance'] <= K.nodes[i]['threshold']:
                        if random.random() < G.nodes[i]['imitation'] * prob:
                            K.nodes[i]['relevance'] = 1
                return K

            dati = [Vl]
            datelli = []
            while t != steps:
                t += 1
                event(K)
                P = []
                for n in K.nodes:
                    if K.nodes[n]['relevance'] >= K.nodes[n]['threshold']:
                        P.append(K.nodes[n]['relevance'])
                        if n not in bellini:
                            bellini.append(n)
                dati.append((len(P) / num))
                datelli.append((len(bellini) / num))

            return [dati, datelli]

        return [degroot(G), contagion(G), bass(G), Vl]

    DATONIdegroot = []
    DATONIcontagion = []
    DATONIbass = []
    DATONIphi = []
    cumulativedegroot = []
    cumulativecontagion = []
    cumulativebass = []
    startTime = time.time()

    while m != iters:
        banana = tutto()
        executiontime=(time.time()-startTime)
        m += 1
        print(int((m/iters)*100),'% Estimated time remaining:', int((((executiontime/(m))*(iters-m)))/60), 'minutes')
        DATONIdegroot.append(banana[0][0])
        DATONIcontagion.append(banana[1][0])
        DATONIbass.append(banana[2][0])
        DATONIphi.append(banana[3])
        cumulativedegroot.append((banana[0][1]))
        cumulativecontagion.append((banana[1][1]))
        cumulativebass.append((banana[2][1]))
    dat = np.array(DATONIdegroot)
    fig, (tot, cumulative, value) = plt.subplots(3, 1)
    for n in dat:
        if n[0] < 1:
            tot.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            tot.plot(n[1:], 'k', alpha=0.1)
    datcumulatividegroot = np.array(cumulativedegroot)
    for n in datcumulatividegroot:
        if n[0] < 1:
            cumulative.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            cumulative.plot(n[1:], 'b', alpha=0.1)
    lst = []
    n = len(tutto()[0][0])
    for i in range(n + 0):
        lst.append(i)
    minimo = []
    massimo = []
    media = []
    mediana = []

    for l in np.array(lst):
        minimo.append(dat[:, l].min())
        massimo.append(dat[:, l].max())
        media.append(dat[:, l].mean())
        mediana.append(np.median(dat[:, l], axis=0))

    value.plot(minimo[1:])
    value.plot(massimo[1:])
    value.plot(media[1:])
    value.plot(mediana[1:], 'r--')

    datcontagion = np.array(DATONIcontagion)
    fig, (tot, cumulative, value) = plt.subplots(3, 1)
    for n in datcontagion:
        if n[0] < 1:
            tot.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            tot.plot(n[1:], 'r', alpha=0.1)
    datcumulativicontagion = np.array(cumulativecontagion)
    for n in datcumulativicontagion:
        if n[0] < 1:
            cumulative.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            cumulative.plot(n[1:], 'r', alpha=0.1)
    lstcontagion = []
    n = len(tutto()[1][0])
    for i in range(n + 0):
        lstcontagion.append(i)
    minimo = []
    massimo = []
    media = []
    mediana = []
    for l in np.array(lstcontagion):
        minimo.append(datcontagion[:, l].min())
        massimo.append(datcontagion[:, l].max())
        media.append(datcontagion[:, l].mean())
        mediana.append(np.median(datcontagion[:, l], axis=0))

    value.plot(minimo[1:])
    value.plot(massimo[1:])
    value.plot(media[1:])
    value.plot(mediana[1:], 'r--')
    datbass = np.array(DATONIbass)
    fig, (tot, cumulative, value) = plt.subplots(3, 1)
    for n in datbass:
        if n[0] < 1:
            tot.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            tot.plot(n[1:], 'k', alpha=0.1)
    datcumulativibass = np.array(cumulativebass)
    for n in datcumulativibass:
        if n[0] < 1:
            cumulative.plot(n[1:], 'k', alpha=0.1)
        if n[0] > 1:
            cumulative.plot(n[1:], 'b', alpha=0.1)
    lstbass = []
    n = len(tutto()[2][0])
    for i in range(n + 0):
        lstbass.append(i)
    minimo = []
    massimo = []
    media = []
    mediana = []

    for l in np.array(lstbass):
        minimo.append(datbass[:, l].min())
        massimo.append(datbass[:, l].max())
        media.append(datbass[:, l].mean())
        mediana.append(np.median(datbass[:, l], axis=0))

    value.plot(minimo[1:])
    value.plot(massimo[1:])
    value.plot(media[1:])
    value.plot(mediana[1:], 'r--')


    



bot = telebot.TeleBot('2125748147:AAHiKWSFJ7vXqFBPLu0qjNYHPuFt1zL3uqo')



print('Bot started...')


data=[]

def step_Set_Price(message):
    cid = message.chat.id
    userPrice= message.text



@bot.message_handler(commands=['start'])
def greet(message):
    bot.reply_to(message,
                 "Ciao! Sono il bot di Sashi. Sono la sua potenziale coscienza cibernetica. "
                 "Sono stata sviluppata in una noiosa domenica. Se vuoi scrivermi, ricordati di scrivere "
                 "correttamente. Evita punteggiatura eccessiva (e.g. !!!) . Evita di essere noiosə."
                 "Sono anche la sua assistente virtuale. "
                 "Se vuoi scoprire quali cose posso fare, chiedimi di mostrarti i /comandi che posso eseguire."
                 "Ti ricordo vuoi esegurie delle analisi, devi contattare il mio collega https://t.me/Nigirizushibot")

@bot.message_handler(commands=['comandi'])
def listacomandi(message):
    bot.reply_to(message,
                 "Qui puoi eseguire una serie di comandi. ecco una lista: \n /contagi \n \n /steps \n \n /amononso."
                 "\n In order to execute a specific analysis, you just need to click on it")

@bot.message_handler(commands=['Go_back_to_menu'])
def listacomandi(message):
    bot.reply_to(message,
                 "Qui puoi eseguire una serie di comandi. ecco una lista: \n /contagi \n \n /steps \n \n /amononso."
                 "\n In order to execute a specific analysis, you just need to click on it")


@bot.message_handler(commands=['contagi'])
def greet(message):
    bot.reply_to(message, "ok, questo dovrebbe darti i grafici. ora proviamo a creare un sub menu."
                 "Excellent choice, dear. This type of analysis will execute the Bass (1969), the DeGroot (1974)"
                 "and the Piccione-Tolotti model (2022) on a randomly generated"
                 "network (Barabasi random graph). Before proceeding, we need to define the parameters necessary."
                 "For instance, we need to define:"
                 "\n The number of nodes on our network; \n The k parameter (da spiegare); \n The number of time steps;\n Finally,"
                 "The number of simulations"
                 "Do you want to proceed?"
                 "\n /Yes_I_want_to_proceed_with_contagion_analysis"
                 "\n /Go_back_to_menu")


@bot.message_handler(commands=['Yes_I_want_to_proceed_with_contagion_analysis'])
def handle_text(message):
    cid = message.chat.id
    msgValuenodes = bot.send_message(cid, 'How many nodes does the network have?')
    bot.register_next_step_handler(msgValuenodes , step_Set_Valuenodes)
    data=[]


def step_Set_Valuenodes(message):
    cid = message.chat.id
    userValuenodes= message.text
    print(userValuenodes)
    msgValuek = bot.send_message(message.chat.id, 'The network will have {} nodes. \n What is the value of k? (suggested, between 1 and 15)'.format(userValuenodes))
    bot.register_next_step_handler(msgValuek, step_Set_Valuek)
    data.append(int(userValuenodes))

def step_Set_Valuek(message):
    cid = message.chat.id
    userValuek= message.text
    print(userValuek)
    msgValuesteps = bot.send_message(message.chat.id, 'The parameter k will have a value of {}. \n How many steps do we want in our simulations?'.format(userValuek))
    bot.register_next_step_handler(msgValuesteps, step_Set_Valuesteps)
    data.append(int(userValuek))

def step_Set_Valuesteps(message):
    cid = message.chat.id
    userValuesteps= message.text
    print(userValuesteps)
    msgValuesimulations = bot.send_message(message.chat.id, 'The number of steps for each simulation will be {}.'
                                           '\n How many times do you want to repeat the simulation?'.format(userValuesteps))
    bot.register_next_step_handler(msgValuesimulations, step_Set_Valuesimulations)
    data.append(int(userValuesteps))

def step_Set_Valuesimulations(message):
    cid = message.chat.id
    userValuesimulations= message.text
    print(userValuesimulations)
    bot.send_message(message.chat.id, "{} simulations will be carried out.".format(userValuesimulations))

    data.append(int(userValuesimulations))
    message_confirmation = bot.send_message(message.chat.id, "Summarizing. \n You want to carry out {} simulations, each of which composed by {} time steps"
                     "regarding the Bass, the DeGroot and the Piccione-Tolotti models on a network of {} nodes built with a k of value."
                     "Do you confirm?".format(data[3],data[2],data[0],data[1]))
    banana = bot.register_next_step_handler(message_confirmation, carryiton)

def carryiton(message):
    if 'Yes' in message.text.split():
        bot.send_message(message.chat.id, "ce l'hai fatta diocane")
        plottare(data[3],data[2],data[0],data[1])

        





    




@bot.message_handler(commands=['steps'])
def greet(message):
    bot.reply_to(message, "qui dovrebbe risponderti con un numero")

@bot.message_handler(commands=['amononso'])
def greet(message):
    bot.reply_to(message, "ma davvero?")


@bot.message_handler()
def send_normal(message):
    if 'Come' in message.text.split():
        bot.send_message(message.chat.id, 'Gaia hai rotto il cazzo con questa risposta di merda')


#while True:
#   bot.polling()
bot.polling(non_stop=False)
